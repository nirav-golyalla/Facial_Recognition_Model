{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from random import shuffle\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy import interp\n",
    "import math\n",
    "from tensorflow import contrib\n",
    "tfe = contrib.eager\n",
    "import tensorflow.python.saved_model\n",
    "from tensorflow.python.saved_model import tag_constants\n",
    "from tensorflow.python.saved_model.signature_def_utils_impl import predict_signature_def\n",
    "\n",
    "from sklearn.model_selection import KFold   \n",
    "\n",
    "#from triplet_loss import batch_all_triplet_loss\n",
    "#from triplet_loss import batch_hard_triplet_loss\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.saved_model import tag_constants\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "from matplotlib.pyplot import figure\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('xml_files/haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('xml_files/haarcascade_eye.xml')\n",
    "\n",
    "Training_Data = r'Chokepoint/jpg'\n",
    "Testing_Data = r'Chokepoint/Video'\n",
    "\n",
    "IMG_SIZE = 96\n",
    "LearningRate = math.pow(10, -4) * 1\n",
    "print(LearningRate)\n",
    "batch_size = 37\n",
    "dropout=0.8\n",
    "peopleNum = 21\n",
    "hm_epochs = 10000\n",
    "file_path = os.getcwd()+'\\model_checkpoints\\model12.ckpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_cropper(img_path):    \n",
    "    img = cv2.imread(img_path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    for (x,y,w,h) in faces:\n",
    "        print(faces)\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = img[y:y+h, x:x+w]\n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "    for (ex,ey,ew,eh) in eyes:\n",
    "        cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "        cv2.imshow('img',img)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "    return img\n",
    "\n",
    "def image_labeler(img):\n",
    "    labelName = img.split('.')[-2]\n",
    "    labelName = labelName.split('-')[-1]\n",
    "    if labelName == 'person1': return [1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "    elif labelName == 'person3': return [0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "    elif labelName == 'person4': return [0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "    elif labelName == 'person5': return [0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "    elif labelName == 'person6': return [0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "    elif labelName == 'person7': return [0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "    elif labelName == 'person9': return [0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "    elif labelName == 'person10': return [0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "    elif labelName == 'person11': return [0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "    elif labelName == 'person12': return [0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0]\n",
    "    elif labelName == 'person13': return [0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0]\n",
    "    elif labelName == 'person14': return [0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0]\n",
    "    elif labelName == 'person15': return [0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0]\n",
    "    elif labelName == 'person16': return [0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0]\n",
    "    elif labelName == 'person17': return [0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0]\n",
    "    elif labelName == 'person18': return [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0]\n",
    "    elif labelName == 'person19': return [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0]\n",
    "    elif labelName == 'person20': return [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0]\n",
    "    elif labelName == 'person21': return [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0]\n",
    "    elif labelName == 'person22': return [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0]\n",
    "    else: return [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1]\n",
    "    \n",
    "def image_labeler_converter(labelName):\n",
    "    if np.array_equal(labelName,[1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]): return 0\n",
    "    elif np.array_equal(labelName,[0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]): return 1\n",
    "    elif np.array_equal(labelName,[0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]): return 2\n",
    "    elif np.array_equal(labelName,[0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]): return 3\n",
    "    elif np.array_equal(labelName,[0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]): return 4\n",
    "    elif np.array_equal(labelName,[0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]): return 5\n",
    "    elif np.array_equal(labelName,[0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0]): return 6\n",
    "    elif np.array_equal(labelName,[0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0]): return 7\n",
    "    elif np.array_equal(labelName,[0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0]): return 8\n",
    "    elif np.array_equal(labelName,[0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0]): return 9\n",
    "    elif np.array_equal(labelName,[0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0]): return 10\n",
    "    elif np.array_equal(labelName,[0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0]): return 11\n",
    "    elif np.array_equal(labelName,[0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0]): return 12\n",
    "    elif np.array_equal(labelName,[0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0]): return 13\n",
    "    elif np.array_equal(labelName,[0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0]): return 14\n",
    "    elif np.array_equal(labelName,[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0]): return 15\n",
    "    elif np.array_equal(labelName,[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0]): return 16\n",
    "    elif np.array_equal(labelName,[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0]): return 17\n",
    "    elif np.array_equal(labelName,[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0]): return 18\n",
    "    elif np.array_equal(labelName,[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0]): return 19\n",
    "    else: return 20\n",
    "\n",
    "\n",
    "def process_test_data():\n",
    "    testing_data = []\n",
    "    for img in tqdm(os.listdir(Testing_Data)):\n",
    "        path = os.path.join(Testing_Data,img)\n",
    "        img_num = img_num.split('.')[-2]\n",
    "        img_num = img_num.split('-')[-2]\n",
    "        img = cv2.imread(path,cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n",
    "        testing_data.append([np.array(img), img_num])\n",
    "\n",
    "    print(testing_data)\n",
    "    shuffle(testing_data)\n",
    "    np.save('test_data.npy', testing_data)\n",
    "    return testing_data\n",
    "\n",
    "def process_images_training_other():\n",
    "    training_data = []\n",
    "    for img in tqdm(os.listdir(Training_Data)):\n",
    "        label = image_labeler(img)\n",
    "        path = os.path.join(Training_Data,img)\n",
    "        img = cv2.imread(path,cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n",
    "        training_data.append([np.array(img), np.array(label)])  \n",
    "\n",
    "    shuffle(training_data)\n",
    "    np.save('training_data/training_data.npy', training_data)\n",
    "    return training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1,1,1,1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "\n",
    "def max_pool_3x3(x):\n",
    "    return tf.nn.max_pool(x,ksize=[1,3,3,1], strides=[1,1,1,1],padding='SAME')\n",
    "\n",
    "def conv_layer(input, shape, bias):\n",
    "    W = weight_variable(shape)\n",
    "    b = bias_variable(bias)\n",
    "    return tf.nn.relu(conv2d(input, W)+b)\n",
    "\n",
    "def full_layer(input, size, bias):\n",
    "    W = weight_variable(size)\n",
    "    b = bias_variable(bias)\n",
    "    return tf.nn.relu(tf.matmul(input, W)+b)\n",
    "\n",
    "def inception_layer(input,input_size,output_size,mid_output):\n",
    "    conv1_1x1 = conv_layer(input,shape = [1,1,input_size,output_size], bias = [output_size])\n",
    "    conv2_1x1 = conv_layer(input,shape = [1,1,input_size,mid_output], bias = [mid_output])\n",
    "    conv3_1x1 = conv_layer(input,shape = [1,1,input_size,mid_output], bias = [mid_output])\n",
    "    maxpool4_3x3 = max_pool_3x3(input)\n",
    "    \n",
    "    conv2_3x3 = conv_layer(conv2_1x1, shape=[3,3,mid_output,output_size],bias = [output_size])\n",
    "    conv3_5x5 = conv_layer(conv3_1x1, shape=[5,5,mid_output,output_size],bias = [output_size])\n",
    "    conv4_1x1 = conv_layer(maxpool4_3x3,shape = [1,1,input_size,output_size], bias = [output_size])\n",
    "    \n",
    "    inception = tf.nn.relu(tf.nn.bias_add(tf.concat([conv1_1x1,conv2_3x3,conv3_5x5,conv4_1x1],3),bias_variable([output_size*4])))\n",
    "    \n",
    "    return inception\n",
    "\n",
    "people = ['person1','person3','person4','person5','person6','person7','person9','person10','person11','person12','person13','person14','person15','person16','person17','person18','person19','person20','person21','person22','unknown',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data = process_images_training_other()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_data[:-333]\n",
    "test = train_data[-333:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_model(data):\n",
    "    #tf.reset_default_graph()\n",
    "    data = tf.reshape(data, shape = [-1,96,96,1])\n",
    "\n",
    "    conv1 = conv_layer(data,shape = [5,5,1,64], bias = [64])\n",
    "    conv1_pool = max_pool_2x2(conv1)\n",
    "    conv2 = conv_layer(conv1_pool, shape=[5,5,64,128],bias = [128])\n",
    "    conv2_pool = max_pool_2x2(conv2)\n",
    "    conv3 = conv_layer(conv2_pool, shape=[5,5,128,256],bias = [256])\n",
    "    conv3_pool = max_pool_2x2(conv3)\n",
    "    conv4 = conv_layer(conv3_pool, shape=[5,5,256,256],bias = [256])\n",
    "    conv4_pool = max_pool_2x2(conv4)\n",
    "    conv5 = conv_layer(conv4_pool, shape=[5,5,256,256],bias = [256])\n",
    "    conv5_pool = max_pool_2x2(conv5)\n",
    "    conv6 = conv_layer(conv5_pool, shape=[5,5,256,256],bias = [256])\n",
    "    conv6_pool = max_pool_2x2(conv6)\n",
    "    \n",
    "    inception1 = inception_layer(conv6_pool,256,128,256)\n",
    "    inception2 = inception_layer(inception1,512,256,128)\n",
    "    inception3 = inception_layer(inception2,1024,64,256)\n",
    "    inception4 = inception_layer(inception3,256,128,64)\n",
    "    inception5 = inception_layer(inception4,512,128,64)\n",
    "    inception6 = inception_layer(inception5,512,256,128)\n",
    "    \n",
    "    inception_pool = max_pool_2x2(inception6)\n",
    "    \n",
    "    conv6_flat = tf.reshape(inception_pool, [-1,1*1*256*4])\n",
    "  \n",
    "    fc_1= full_layer(conv6_flat, [1*1*256*4, 2048], [2048])\n",
    "    fc_1 = tf.nn.dropout(fc_1, dropout)\n",
    "    fc_2= full_layer(fc_1, [2048, 2048], [2048])\n",
    "    fc_2 = tf.nn.dropout(fc_2, dropout)\n",
    "    output = tf.matmul(fc_2, weight_variable([2048, peopleNum])) + bias_variable([peopleNum])\n",
    "    print(output)\n",
    "    return output\n",
    "\n",
    "def training_CNN_triplet(x):   \n",
    "    prediction = true_model(x)\n",
    "    tf.identity(prediction, name=\"Output_ph\")\n",
    "    cost = tf.reduce_mean( tf.losses.softmax_cross_entropy(logits=prediction, onehot_labels= y_) )\n",
    "    optimizer = tf.train.AdamOptimizer(LearningRate).minimize(cost)\n",
    "    correct = tf.equal(tf.argmax(prediction, 1), tf.argmax(y_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))       \n",
    "    loss_list = []\n",
    "    training_acc_list = []\n",
    "    test_acc_list = []\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for epoch in range(hm_epochs):\n",
    "            epoch_loss = 0\n",
    "            i = 0\n",
    "            while i < len(train):\n",
    "                start = i \n",
    "                end = i + batch_size\n",
    "\n",
    "                batch_x = np.array(X_data[start:end])\n",
    "                batch_y = np.array(Y_labels[start:end])\n",
    "\n",
    "                _, c = sess.run([optimizer,cost], feed_dict={x: batch_x, y_: batch_y})\n",
    "                epoch_loss += c\n",
    "                i+= batch_size\n",
    "            print('Epoch', epoch+1, 'completed out of',hm_epochs,'loss:',epoch_loss)\n",
    "            loss_list.append(epoch_loss)\n",
    "            if (epoch+1)%1 == 0:\n",
    "                training_acc_list.append(training_acc_CNN(sess, accuracy))\n",
    "                test_acc_list.append(validation_acc_CNN(sess, accuracy))\n",
    "\n",
    "        predictions = prediction.eval(feed_dict={x: cX_data}, session=sess)\n",
    "        \n",
    "        \n",
    "        plt.plot(loss_list)\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title(\"Loss History\")\n",
    "        plt.show()\n",
    "        plt.plot(training_acc_list)\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title(\"Training Accuracy\")\n",
    "        plt.show()\n",
    "        plt.plot(test_acc_list)\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title(\"Testing Accuracy\")\n",
    "        plt.show()\n",
    "        roc_auc_graph(\"Testing\",predictions,cY_labels) \n",
    "        confusion_matrix_make(sess,predictions,cY_labels)\n",
    "\n",
    "        precision_recall(sess,predictions,cY_labels)\n",
    "        perf_measure(cY_labels, predictions)\n",
    "        \n",
    "        live_prediction(sess,prediction)\n",
    "        \n",
    "        print('\\nSaving...')\n",
    "        inputs_dict = {\n",
    "            \"features_data_ph\": x,\n",
    "            \"labels_data_ph\": y_\n",
    "        }\n",
    "        outputs_dict = {\n",
    "            \"Output_ph\": prediction\n",
    "        }\n",
    "        #tf.saved_model.simple_save(sess, file_path, inputs_dict, outputs_dict)\n",
    "        print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_acc_CNN(sess, accuracy):     \n",
    "    training_accuracy_results = []\n",
    "    cls_pred = np.zeros(shape=len(test), dtype=np.int)\n",
    "    i = 0\n",
    "    while i < len(test):\n",
    "        start = i \n",
    "        end = i + batch_size\n",
    "\n",
    "        batch_x = np.array(X_data[start:end])\n",
    "        batch_y = np.array(Y_labels[start:end])\n",
    "\n",
    "        training_accuracy_results.append(sess.run(accuracy, feed_dict={x: batch_x, y_: batch_y})) \n",
    "        i+= batch_size\n",
    "        \n",
    "    acc = np.mean(training_accuracy_results)\n",
    "    print(\"Training Accuracy: {}\".format(acc *100))\n",
    "    return acc\n",
    "def validation_acc_CNN(sess, accuracy):     \n",
    "    validation_accuracy_results = []\n",
    "    cls_pred = np.zeros(shape=len(test), dtype=np.int)\n",
    "    i = 0\n",
    "    while i < len(test):\n",
    "        start = i \n",
    "        end = i + batch_size\n",
    "\n",
    "        batch_x = np.array(cX_data[start:end])\n",
    "        batch_y = np.array(cY_labels[start:end])\n",
    "\n",
    "        validation_accuracy_results.append(sess.run(accuracy, feed_dict={x: batch_x, y_: batch_y})) \n",
    "        i+= batch_size\n",
    "        \n",
    "    acc = np.mean(validation_accuracy_results)\n",
    "    print(\"Validation Accuracy: {}\".format(acc*100))\n",
    "    return acc\n",
    "    \n",
    "def roc_auc_graph(typ,predictions,labels):\n",
    "    test = []\n",
    "    for i in range(len(labels)):\n",
    "        test.append(image_labeler_converter(labels[i]))\n",
    "    test = label_binarize(test, classes=[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20])\n",
    "    fpr, tpr, _ = roc_curve(test.ravel(), predictions.ravel())\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    print('roc_auc: {}'.format(roc_auc))\n",
    "    figure(num=None, figsize=(4, 3), dpi=80, facecolor='w', edgecolor='k')\n",
    "    lw = 2\n",
    "    plt.plot(fpr, tpr, color='darkorange',\n",
    "             lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('{} Receiver operating characteristic'.format(typ))\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_confusion_matrix(cm,names, title='Confusion matrix', cmap=plt.cm.Blues,normalize=False):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(names))\n",
    "    plt.xticks(tick_marks, names, rotation=90)\n",
    "    plt.yticks(tick_marks, names)\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "    \n",
    "def confusion_matrix_make(typ,prediction,labels):\n",
    "    test = []\n",
    "    for i in range(len(labels)):\n",
    "        test.append(image_labeler_converter(labels[i]))\n",
    "    test = label_binarize(test, classes=[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20])\n",
    "    y_test2 = np.argmax(test,axis=1)\n",
    "    pred = np.argmax(prediction,axis=1)\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_test2, pred, labels = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20])\n",
    "    np.set_printoptions(precision=2)\n",
    "    \n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    print('Normalized confusion matrix')\n",
    "\n",
    "    figure(num=None, figsize=(4,4), dpi=80, facecolor='w', edgecolor='k')\n",
    "    plot_confusion_matrix(cm_normalized, people, title='{} Normalized confusion matrix'.format(typ), normalize = True)\n",
    "\n",
    "    plt.show()\n",
    "        \n",
    "def precision_recall(typ,predictions,labels):\n",
    "    test = []\n",
    "    for i in range(len(labels)):\n",
    "        test.append(image_labeler_converter(labels[i]))\n",
    "    test = label_binarize(test, classes=[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20])\n",
    "    precision, recall, _ = precision_recall_curve(test.ravel(), predictions.ravel())\n",
    "    \n",
    "    print('precision: {}'.format(precision))\n",
    "    print('recall: {}'.format(recall))\n",
    "    \n",
    "    \n",
    "    average_precision = average_precision_score(test.ravel(), predictions.ravel())\n",
    "    print('Average precision score, micro-averaged over all classes: {0:0.2f}'.format(average_precision))\n",
    "    \n",
    "    figure(num=None, figsize=(4, 3), dpi=80, facecolor='w', edgecolor='k')\n",
    "    plt.step(recall, precision, color='b', alpha=0.2,\n",
    "             where='post')\n",
    "    plt.fill_between(recall, precision, alpha=0.2, color='b')\n",
    "\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.title('{typ} Average precision score, micro-averaged over all classes: AP={average_precision}'\n",
    "        .format(average_precision=average_precision,typ=typ))\n",
    "    \n",
    "def perf_measure(labels, prediction):\n",
    "    test = []\n",
    "    for i in range(len(labels)):\n",
    "        test.append(image_labeler_converter(labels[i]))\n",
    "    test = label_binarize(test, classes=[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20])\n",
    "    y_test2 = np.argmax(test,axis=1)\n",
    "    pred = np.argmax(prediction,axis=1)\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_test2, pred, labels = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20])\n",
    "    FP = cm.sum(axis=0) - np.diag(cm)  \n",
    "    FN = cm.sum(axis=1) - np.diag(cm)\n",
    "    TP = np.diag(cm)\n",
    "    TN = cm.sum() - (FP + FN + TP)\n",
    "    print('tp: {}'.format(TP))\n",
    "    print('fp: {}'.format(FP))\n",
    "    print('tN: {}'.format(TN))\n",
    "    print('fn: {}'.format(FN)) \n",
    "    \n",
    "    \n",
    "def live_prediction(sess,prediction):\n",
    "    fig=plt.figure()\n",
    "\n",
    "    for num,data in enumerate(test[:12]):\n",
    "        img_num = data[1]\n",
    "        img_data = data[0]\n",
    "\n",
    "        y = fig.add_subplot(3,4,num+1)\n",
    "        orig = img_data\n",
    "        data = img_data.reshape(IMG_SIZE,IMG_SIZE,1)\n",
    "        \n",
    "        model_out = prediction.eval(feed_dict={x: [data]}, session=sess)\n",
    "        if np.argmax(model_out) == 0: str_label='person1'\n",
    "        elif np.argmax(model_out) == 1: str_label='person3'\n",
    "        elif np.argmax(model_out) == 2: str_label='person4'\n",
    "        elif np.argmax(model_out) == 3: str_label='person5'\n",
    "        elif np.argmax(model_out) == 4: str_label='person6'\n",
    "        elif np.argmax(model_out) == 5: str_label='person7'\n",
    "        elif np.argmax(model_out) == 6: str_label='person9'\n",
    "        elif np.argmax(model_out) == 7: str_label='person10'\n",
    "        elif np.argmax(model_out) == 8: str_label='person11'\n",
    "        elif np.argmax(model_out) == 9: str_label='person12'\n",
    "        elif np.argmax(model_out) == 10: str_label='person13'\n",
    "        elif np.argmax(model_out) == 11: str_label='person14'\n",
    "        elif np.argmax(model_out) == 12: str_label='person15'\n",
    "        elif np.argmax(model_out) == 13: str_label='person16'\n",
    "        elif np.argmax(model_out) == 14: str_label='person17'\n",
    "        elif np.argmax(model_out) == 15: str_label='person18'\n",
    "        elif np.argmax(model_out) == 16: str_label='person19'\n",
    "        elif np.argmax(model_out) == 17: str_label='person20'\n",
    "        elif np.argmax(model_out) == 18: str_label='person21'\n",
    "        elif np.argmax(model_out) == 19: str_label='person22'\n",
    "        else: str_label='unknown'\n",
    "\n",
    "        y.imshow(orig,cmap='gray')\n",
    "        plt.title(str_label)\n",
    "        y.axes.get_xaxis().set_visible(False)\n",
    "        y.axes.get_yaxis().set_visible(False)\n",
    "    plt.show()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None,96,96,1], name='placeholder_input')\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, peopleNum], name='placeholder_labels') \n",
    "\n",
    "y_true_cls = tf.argmax(y_, axis=1)\n",
    "\n",
    "X_data = np.array([i[0] for i in train]).reshape(-1, IMG_SIZE,IMG_SIZE, 1)   \n",
    "Y_labels = [i[1] for i in train]\n",
    "\n",
    "cX_data = np.array([i[0] for i in test]).reshape(-1, IMG_SIZE,IMG_SIZE, 1)   \n",
    "cY_labels = [i[1] for i in test]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_CNN_triplet(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
